{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40fc291d",
   "metadata": {},
   "source": [
    "AP22110010128 | Krishna Sharma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60999637",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import re\n",
    "from collections import defaultdict, Counter\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "605cab5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    \"machine learning algorithms use neural networks to process data and make predictions\",\n",
    "    \"artificial intelligence involves deep learning models trained on large datasets\", \n",
    "    \"computer vision algorithms analyze images using convolutional neural networks\",\n",
    "    \"natural language processing uses transformers and neural networks for text analysis\",\n",
    "    \"data science combines statistics machine learning and programming to extract insights\",\n",
    "    \"deep learning models require extensive training data and computational resources\",\n",
    "    \"supervised learning algorithms learn from labeled training data to make predictions\",\n",
    "    \"unsupervised learning finds patterns in data without labeled examples\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94216550",
   "metadata": {},
   "source": [
    "Binary Independence Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bccf48d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"neural networks deep learning\"\n",
    "query_terms = set(re.findall(r'\\b\\w+\\b', query.lower()))\n",
    "\n",
    "inverted_index = defaultdict(set)\n",
    "for doc_id, doc in enumerate(documents):\n",
    "    terms = re.findall(r'\\b\\w+\\b', doc.lower())\n",
    "    for term in set(terms):\n",
    "        inverted_index[term].add(doc_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22a502b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(documents)\n",
    "bim_scores = {}\n",
    "\n",
    "for doc_id in range(N):\n",
    "    score = 0\n",
    "    for term in query_terms:\n",
    "        if term in inverted_index:\n",
    "            df = len(inverted_index[term])  \n",
    "            if doc_id in inverted_index[term]:\n",
    "                score += math.log((N - df + 0.5) / (df + 0.5))\n",
    "    bim_scores[doc_id] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba166e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: 'neural networks deep learning'\n",
      "\n",
      "Rank 1 (Score: 0.9040):\n",
      "  Document 2: computer vision algorithms analyze images using convolutional neural networks\n",
      "\n",
      "Rank 2 (Score: 0.9040):\n",
      "  Document 3: natural language processing uses transformers and neural networks for text analysis\n",
      "\n",
      "Rank 3 (Score: 0.0000):\n",
      "  Document 1: artificial intelligence involves deep learning models trained on large datasets\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bim_ranked = sorted(bim_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(f\"Query: '{query}'\\n\")\n",
    "for rank, (doc_id, score) in enumerate(bim_ranked[:3], 1):\n",
    "    print(f\"Rank {rank} (Score: {score:.4f}):\")\n",
    "    print(f\"  Document {doc_id}: {documents[doc_id]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe96775",
   "metadata": {},
   "source": [
    "Okapi BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62f146b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "query2 = \"data analysis machine learning\"\n",
    "query2_terms = re.findall(r'\\b\\w+\\b', query2.lower())\n",
    "\n",
    "k1 = 1.5\n",
    "b = 0.75\n",
    "\n",
    "doc_terms = [re.findall(r'\\b\\w+\\b', doc.lower()) for doc in documents]\n",
    "\n",
    "avg_dl = sum(len(doc) for doc in doc_terms) / N\n",
    "\n",
    "df = defaultdict(int)\n",
    "for doc in doc_terms:\n",
    "    for term in set(doc):\n",
    "        df[term] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0836f9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_scores = {}\n",
    "for doc_id, doc in enumerate(doc_terms):\n",
    "    score = 0\n",
    "    dl = len(doc)\n",
    "    term_freq = Counter(doc)\n",
    "    \n",
    "    for term in query2_terms:\n",
    "        if term in term_freq:\n",
    "            tf = term_freq[term]\n",
    "            df_term = df[term]\n",
    "            \n",
    "            idf = math.log((N - df_term + 0.5) / (df_term + 0.5) + 1.0)\n",
    "            \n",
    "            numerator = tf * (k1 + 1)\n",
    "            denominator = tf + k1 * (1 - b + b * (dl / avg_dl))\n",
    "            score += idf * (numerator / denominator)\n",
    "    \n",
    "    bm25_scores[doc_id] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e0bf1cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: 'data analysis machine learning'\n",
      "\n",
      "Rank 1 (Score: 2.0434):\n",
      "  Document 4: data science combines statistics machine learning and programming to extract insights\n",
      "\n",
      "Rank 2 (Score: 1.9606):\n",
      "  Document 0: machine learning algorithms use neural networks to process data and make predictions\n",
      "\n",
      "Rank 3 (Score: 1.7445):\n",
      "  Document 3: natural language processing uses transformers and neural networks for text analysis\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bm25_ranked = sorted(bm25_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(f\"Query: '{query2}'\\n\")\n",
    "for rank, (doc_id, score) in enumerate(bm25_ranked[:3], 1):\n",
    "    print(f\"Rank {rank} (Score: {score:.4f}):\")\n",
    "    print(f\"  Document {doc_id}: {documents[doc_id]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b89ae5b",
   "metadata": {},
   "source": [
    "Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3498398",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    \"machine learning algorithms use neural networks\",\n",
    "    \"deep learning models trained on datasets\",\n",
    "    \"neural networks process data efficiently\",\n",
    "    \"convolutional networks analyze images\",\n",
    "    \"supervised learning uses labeled data\",\n",
    "    \"python programming language for data science\",\n",
    "    \"javascript web development framework\",\n",
    "    \"java object oriented programming\",\n",
    "    \"c++ systems programming language\",\n",
    "    \"ruby on rails web application\",\n",
    "    \"data visualization with matplotlib\",\n",
    "    \"statistical analysis using python\",\n",
    "    \"database query optimization techniques\",\n",
    "    \"sql joins and aggregations\",\n",
    "    \"nosql document databases\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10a3ff8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2]\n",
    "label_names = ['Machine Learning', 'Programming', 'Data/Database']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    texts, labels, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=50)\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aacc9a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4000\n",
      "\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Machine Learning       0.25      1.00      0.40         1\n",
      "     Programming       1.00      0.50      0.67         2\n",
      "   Data/Database       0.00      0.00      0.00         2\n",
      "\n",
      "        accuracy                           0.40         5\n",
      "       macro avg       0.42      0.50      0.36         5\n",
      "    weighted avg       0.45      0.40      0.35         5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Computer Science\\AIMLDL\\AI-ML-DL\\ML-Lab\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Computer Science\\AIMLDL\\AI-ML-DL\\ML-Lab\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Computer Science\\AIMLDL\\AI-ML-DL\\ML-Lab\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "classifier = MultinomialNB()\n",
    "classifier.fit(X_train_vec, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test_vec)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95886cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictions on new documents:\n",
      "  'neural networks for deep learning' -> Machine Learning\n",
      "  'python programming tutorial' -> Programming\n",
      "  'database management system' -> Data/Database\n"
     ]
    }
   ],
   "source": [
    "test_docs = [\n",
    "    \"neural networks for deep learning\",\n",
    "    \"python programming tutorial\",\n",
    "    \"database management system\"\n",
    "]\n",
    "\n",
    "test_vec = vectorizer.transform(test_docs)\n",
    "predictions = classifier.predict(test_vec)\n",
    "\n",
    "print(\"\\nPredictions on new documents:\")\n",
    "for doc, pred in zip(test_docs, predictions):\n",
    "    print(f\"  '{doc}' -> {label_names[pred]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d84ef4",
   "metadata": {},
   "source": [
    "Text Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c8531e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clusters: 3\n"
     ]
    }
   ],
   "source": [
    "vectorizer2 = TfidfVectorizer(max_features=50)\n",
    "X = vectorizer2.fit_transform(documents)\n",
    "\n",
    "n_clusters = 3\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "clusters = kmeans.fit_predict(X)\n",
    "\n",
    "print(f\"Number of clusters: {n_clusters}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b8fd705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0:\n",
      "  Doc 2: computer vision algorithms analyze images using convolutional neural networks\n",
      "  Doc 3: natural language processing uses transformers and neural networks for text analysis\n",
      "Cluster 1:\n",
      "  Doc 0: machine learning algorithms use neural networks to process data and make predictions\n",
      "  Doc 4: data science combines statistics machine learning and programming to extract insights\n",
      "  Doc 6: supervised learning algorithms learn from labeled training data to make predictions\n",
      "  Doc 7: unsupervised learning finds patterns in data without labeled examples\n",
      "Cluster 2:\n",
      "  Doc 1: artificial intelligence involves deep learning models trained on large datasets\n",
      "  Doc 5: deep learning models require extensive training data and computational resources\n"
     ]
    }
   ],
   "source": [
    "cluster_docs = defaultdict(list)\n",
    "for doc_id, cluster_id in enumerate(clusters):\n",
    "    cluster_docs[cluster_id].append((doc_id, documents[doc_id]))\n",
    "\n",
    "for cluster_id in sorted(cluster_docs.keys()):\n",
    "    print(f\"Cluster {cluster_id}:\")\n",
    "    for doc_id, doc in cluster_docs[cluster_id]:\n",
    "        print(f\"  Doc {doc_id}: {doc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a217f484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms per cluster:\n",
      "  Cluster 0: neural, networks, convolutional, computer, analyze\n",
      "  Cluster 1: data, to, learning, labeled, make\n",
      "  Cluster 2: deep, models, computational, extensive, require\n"
     ]
    }
   ],
   "source": [
    "order_centroids = kmeans.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = vectorizer2.get_feature_names_out()\n",
    "\n",
    "print(\"Top terms per cluster:\")\n",
    "for cluster_id in range(n_clusters):\n",
    "    top_terms = [terms[ind] for ind in order_centroids[cluster_id, :5]]\n",
    "    print(f\"  Cluster {cluster_id}: {', '.join(top_terms)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24020bbc",
   "metadata": {},
   "source": [
    "AP22110010128 | Krishna Sharma"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
