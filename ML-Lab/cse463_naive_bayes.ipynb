{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes on Categorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "data_size = 1000\n",
    "\n",
    "feature_a = np.random.choice(['A', 'B', 'C'], data_size)\n",
    "feature_b = np.random.choice(['X', 'Y', 'Z'], data_size)\n",
    "feature_c = np.random.choice(['M', 'N'], data_size)\n",
    "feature_d = np.random.choice(['P', 'Q'], data_size)\n",
    "labels = np.random.choice([0, 1], data_size)\n",
    "\n",
    "df = pd.DataFrame({'FeatureA': feature_a, 'FeatureB': feature_b, 'FeatureC': feature_c, 'FeatureD': feature_d, 'Label': labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_probs = defaultdict(lambda: defaultdict(lambda: defaultdict(float)))\n",
    "class_probs = train_data['Class'].value_counts(normalize=True).to_dict()\n",
    "\n",
    "for col in train_data.columns[:-1]:\n",
    "    for label in [0, 1]:\n",
    "        subset = train_data[train_data['Class'] == label]\n",
    "        value_counts = subset[col].value_counts(normalize=True).to_dict()\n",
    "        for val, prob in value_counts.items():\n",
    "            feature_probs[col][val][label] = prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = test_data['Class'].values\n",
    "y_pred = []\n",
    "\n",
    "for _, row in test_data.iterrows():\n",
    "    scores = {}\n",
    "    for label in [0, 1]:\n",
    "        prob = class_probs[label]\n",
    "        for col in test_data.columns[:-1]:\n",
    "            prob *= feature_probs[col].get(row[col], {}).get(label, 1e-6)\n",
    "        scores[label] = prob\n",
    "    y_pred.append(max(scores, key=scores.get))\n",
    "\n",
    "y_pred = np.array(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.4420\n",
      "Recall: 0.6854\n",
      "F1-Score: 0.5374\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes on Continuous Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "data_size = 1000\n",
    "\n",
    "feature_a = np.random.randint(1, 11, data_size)\n",
    "feature_b = np.random.randint(5, 16, data_size)\n",
    "feature_c = np.random.randint(0, 6, data_size)\n",
    "feature_d = np.random.randint(1, 21, data_size)\n",
    "labels = np.random.choice([0, 1], data_size)\n",
    "\n",
    "df = pd.DataFrame({'FeatureA': feature_a, 'FeatureB': feature_b, 'FeatureC': feature_c, 'FeatureD': feature_d, 'Label': labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_std = {}\n",
    "class_probs = {}\n",
    "\n",
    "class_counts = train_data['Class'].value_counts()\n",
    "total_samples = len(train_data)\n",
    "for label in class_counts.index:\n",
    "    class_probs[label] = class_counts[label] / total_samples\n",
    "\n",
    "for col in train_data.columns[:-1]:\n",
    "    mean_std[col] = {}\n",
    "    for label in class_counts.index:\n",
    "        subset = train_data[train_data['Class'] == label][col]\n",
    "        mean_std[col][label] = (subset.mean(), subset.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = test_data['Class'].values\n",
    "y_pred = []\n",
    "\n",
    "for _, row in test_data.iterrows():\n",
    "    scores = {}\n",
    "    for label in class_probs:\n",
    "        prob = class_probs[label]\n",
    "        for col in test_data.columns[:-1]:\n",
    "            mean, std = mean_std[col][label]\n",
    "            exponent = math.exp(-((row[col] - mean) ** 2) / (2 * (std ** 2)))\n",
    "            probability_density = (1 / (math.sqrt(2 * math.pi) * std)) * exponent\n",
    "            prob *= probability_density\n",
    "        scores[label] = prob\n",
    "    y_pred.append(max(scores, key=scores.get))\n",
    "\n",
    "y_pred = np.array(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.4444\n",
      "Recall: 0.3404\n",
      "F1-Score: 0.3855\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
